Model:
  encoding: r50k_base
  model_max_len: 512
  num_stacks: 6
  embed_dim: 1024
  num_heads: 16
  ff_dim: 4096
  dropout: 0.3

Training:
  batch_size: 12
  grad_accumulation_steps: 16
  learning_rate: 4e-4
  warmup_steps: 3000
  epochs: 10
  label_smoothing: 0.1
  num_samples: 500000
  log_interval: 50
